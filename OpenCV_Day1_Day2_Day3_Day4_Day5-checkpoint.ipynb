{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002fd72d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(cv2\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89909b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/38/d2/3e8c13ffc37ca5ebc6f382b242b44acb43eb489042e1728407ac3904e72f/opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\veena\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/38.1 MB 7.6 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.7/38.1 MB 7.7 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.1/38.1 MB 7.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.3/38.1 MB 7.6 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.6/38.1 MB 7.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.9/38.1 MB 6.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.3/38.1 MB 7.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.6/38.1 MB 6.9 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.0/38.1 MB 7.0 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.4/38.1 MB 7.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.7/38.1 MB 7.2 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.0/38.1 MB 7.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.2/38.1 MB 7.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.4/38.1 MB 6.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 4.8/38.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.2/38.1 MB 6.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.4/38.1 MB 6.5 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 5.7/38.1 MB 6.5 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.0/38.1 MB 6.5 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.4/38.1 MB 6.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 6.7/38.1 MB 6.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 6.8/38.1 MB 6.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.2/38.1 MB 6.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.5/38.1 MB 6.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 7.8/38.1 MB 6.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 7.9/38.1 MB 6.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.2/38.1 MB 6.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.5/38.1 MB 6.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 8.8/38.1 MB 6.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 9.0/38.1 MB 6.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 9.1/38.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 9.5/38.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 9.9/38.1 MB 6.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 10.3/38.1 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 10.6/38.1 MB 6.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 10.8/38.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 11.1/38.1 MB 6.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 11.4/38.1 MB 6.1 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 11.6/38.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 11.9/38.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 12.3/38.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 12.7/38.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 12.9/38.1 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 13.4/38.1 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 13.6/38.1 MB 6.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 13.9/38.1 MB 6.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 14.2/38.1 MB 6.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 14.6/38.1 MB 6.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 14.9/38.1 MB 6.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 15.4/38.1 MB 6.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 15.8/38.1 MB 6.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 16.4/38.1 MB 6.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 16.7/38.1 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 17.2/38.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 17.5/38.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 17.8/38.1 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 18.1/38.1 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.5/38.1 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.8/38.1 MB 6.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.1/38.1 MB 6.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.4/38.1 MB 7.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.7/38.1 MB 7.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.2/38.1 MB 7.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.7/38.1 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.0/38.1 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.5/38.1 MB 7.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 21.9/38.1 MB 7.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.5/38.1 MB 7.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.8/38.1 MB 7.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.2/38.1 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.7/38.1 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.1/38.1 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.4/38.1 MB 7.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 24.8/38.1 MB 7.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.3/38.1 MB 7.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 25.8/38.1 MB 7.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.3/38.1 MB 7.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 7.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.1/38.1 MB 7.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.5/38.1 MB 7.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.0/38.1 MB 7.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.3/38.1 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 28.7/38.1 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.2/38.1 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.5/38.1 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.0/38.1 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.4/38.1 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 30.8/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.2/38.1 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 31.6/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 31.9/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.3/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 32.7/38.1 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.1/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 33.5/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 33.9/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.3/38.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.7/38.1 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.1/38.1 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.4/38.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.9/38.1 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.2/38.1 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.6/38.1 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.9/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.3/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.6/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 6.4 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.1.78\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd12575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a01e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((1400,800,3),dtype=np.uint8)\n",
    "cv2.line(image,(100,100),(50,50),(123,235,215),6)\n",
    "cv2.imshow(\"TestImages2 for crashing\",image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f467ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((1400,800,3),dtype=np.uint8)\n",
    "cv2.rectangle(image, (50, 100), (250, 200), (0, 0, 255), 3) \n",
    "cv2.imshow(\"TestImages2 for crashing\",image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b69fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((1400,800,3),dtype=np.uint8)\n",
    "cv2.circle(image, (400, 150), 50, (255, 0, 0), -1)\n",
    "cv2.imshow(\"TestImages2 for crashing\",image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f87a41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((1400,800,3),dtype=np.uint8)\n",
    "cv2.line(image,(100,100),(50,50),(123,235,215),6)\n",
    "cv2.rectangle(image, (50, 100), (250, 200), (0, 0, 255), 3) \n",
    "cv2.circle(image, (400, 150), 50, (255, 0, 0), 10)\n",
    "cv2.imshow(\"TestImages2 for crashing\",image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee3cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((1400,800,3),dtype=np.uint8)\n",
    "cv2.rectangle(image, (600, 300), (450, 300), (255, 0, 0), 3) \n",
    "cv2.circle(image, (300, 250), 100, (255, 255, 255), -1)\n",
    "cv2.imshow(\"TestImages2 for crashing\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc0191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = np.zeros((1400, 800, 3), dtype=np.uint8)\n",
    "cv2.rectangle(image, (200, 100), (600, 400), (0, 0,255), -1)  \n",
    "cv2.circle(image, (400, 250), 80, (255, 255, 255), -1)  \n",
    "cv2.imshow(\"Rectangle with Circle\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8625b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/hp.jpg\")\n",
    "cvtd=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.imshow(\"Grayscale Image\",cvtd)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4df2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/hp.jpg\")\n",
    "cvtd=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "cvtd1=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cvtd2=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "cvtd3=cv2.cvtColor(image,cv2.COLOR_BGR2LAB)\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.imshow(\"RGB Image\",cvtd)\n",
    "cv2.imshow(\"GrayScale Image\",cvtd1)\n",
    "cv2.imshow(\"HSV Image\",cvtd2)\n",
    "cv2.imshow(\"LAB Image\",cvtd3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999108fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "original_image = cv2.imread(\"C:/Users/Veena/Downloads/hp.jpg\")\n",
    "\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "\n",
    "# Convert BGR to RGB\n",
    "# OpenCV reads in BGR by default\n",
    "rgb_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cv2.imshow(\"RGB Image\", rgb_image)\n",
    "\n",
    "# Convertfrom RGB to grayscale\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Grayscale Image\", gray_image)\n",
    "\n",
    "# Convertfrom BGR to HSV\n",
    "hsv_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"HSV Image\", hsv_image)\n",
    "\n",
    "# Convert from BGR to LAB\n",
    "lab_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Display the image in LAB colorspace\n",
    "cv2.imshow(\"LAB Image\", lab_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65f49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/hp.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the dimesions of image\n",
    "import cv2\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/hp.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e26c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/hp.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "width,height=image.shape[:2]\n",
    "zoom=int(input())\n",
    "rotation_center=(width//2,height//2)\n",
    "rotation_angle=180 #in Degrees\n",
    "rotation_matrix = cv2.getRotationMatrix2D(rotation_center,rotation_angle, zoom)  \n",
    "# 1 is the scale factor\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.imshow(\"Transformed Image\",rotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4987b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 0.5\n",
    "scaled_image = cv2.resize(image, None, fx=scaling_factor, fy=scaling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5db9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image = cv2.resize(image, (280,260))\n",
    "scaled_image1 = cv2.resize(image, None,fx=1.2,fy=2.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34301d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/hp.jpg\")\n",
    "resized_image = cv2.resize(image, (350,450))\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Resized Image\", resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3812d",
   "metadata": {},
   "source": [
    "# DAY-2_OPENCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9361522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/HP1.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow('Original Grayscale Image', image)\n",
    "\n",
    "threshold_value = 127  # Threshold value\n",
    "_, binary_threshold_image = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('Binary Threshold Image', binary_threshold_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/HP1.jpg\")\n",
    "cvtd=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "cvtd1=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cvtd2=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "cvtd3=cv2.cvtColor(image,cv2.COLOR_BGR2LAB)\n",
    "colorImage = cv2.bilateralFilter(originalmage, 9, 300, 300)\n",
    "ReSized5 = cv2.resize(colorImage, (960, 540))\n",
    "blurred_image = cv2.GaussianBlur(image, (7, 7), 0)\n",
    "cv2.imshow(\"Blurred Image\", blurred_image)\n",
    "edges_image = cv2.Canny(grayscale_image, 50, 150)\n",
    "cv2.imshow(\"Edges Detection\", edges_image)\n",
    "cv2.imshow(\"Original Image\",image)\n",
    "cv2.imshow(\"RGB Image\",cvtd)\n",
    "cv2.imshow(\"GrayScale Image\",cvtd1)\n",
    "cv2.imshow(\"HSV Image\",cvtd2)\n",
    "cv2.imshow(\"LAB Image\",cvtd3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09896a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg)\n",
    "\n",
    "blue_overlay = np.zeros_like(image)\n",
    "blue_overlay[:, :] = [100, 26, 26]  # Blue (BGR format)\n",
    "\n",
    "alpha = 0.5  # 0.0: fully transparent, 1.0: fully opaque\n",
    "\n",
    "# Blend the image with the blue overlay\n",
    "result_image = cv2.addWeighted(image, 1 - alpha, blue_overlay, alpha, 0)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Blue Image', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fadfd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image blending ,overlay\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "\n",
    "blue_overlay = np.zeros_like(image)\n",
    "blue_overlay[:, :] = [100,26,26]  # Blue (BGR format)\n",
    "blueoverlay[:, :] = [77,100,26]  # Blue (BGR format)\n",
    "\n",
    "alpha = 0.5  # 0.0: fully transparent, 1.0: fully opaque\n",
    "alpha1=0.9\n",
    "# Blend the image with the blue overlay\n",
    "result_image = cv2.addWeighted(image, 1 - alpha, blue_overlay, alpha, 0)\n",
    "resultimage=cv2.addWeighted(image, 1 - alpha1, blueoverlay, alpha, 0)\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Blue Image', result_image)\n",
    "cv2.imshow('Image2',resultimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "\n",
    "# Average Blurring: Replacing each pixel value with the average value of its neighborhood\n",
    "kernel_size = (25, 25)  # Kernel size for the average blur filter\n",
    "average_blur_image = cv2.blur(image, kernel_size)\n",
    "\n",
    "cv2.imshow('Average Blurred Image', average_blur_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934422cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#black and white image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/hp.jpg')\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "\n",
    "# Average Blurring: Replacing each pixel value with the average value of its neighborhood\n",
    "kernel_size = (30, 30)  # Kernel size for the average blur filter\n",
    "average_blur_image = cv2.blur(image, kernel_size)\n",
    "\n",
    "cv2.imshow('Average Blurred Image', average_blur_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b075db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian_blur_image = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "\n",
    "# Average Blurring: Replacing each pixel value with the average value of its neighborhood\n",
    "kernel_size = (30, 30)  # Kernel size for the average blur filter\n",
    "average_blur_image = cv2.blur(image, kernel_size)\n",
    "gaussian_blur_image = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "cv2.imshow('Average Blurred Image', average_blur_image)\n",
    "cv2.imshow('Gaussian image',gaussian_blur_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c32b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "\n",
    "#cv2.imshow('Original Image', image)\n",
    "\n",
    "# Average Blurring: Replacing each pixel value with the average value of its neighborhood\n",
    "kernel_size = (25, 25)  # Kernel size for the average blur filter\n",
    "average_blur_image = cv2.blur(image, kernel_size)\n",
    "gaussian_blur_image = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "median_blur_image = cv2.medianBlur(image, 25)\n",
    "cv2.imshow('Gaussian Blurred Image', gaussian_blur_image)\n",
    "cv2.imshow('Average Blurred Image', average_blur_image)\n",
    "cv2.imshow('Median Blurred Image', median_blur_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "\n",
    "blue_overlay = np.zeros_like(image)\n",
    "blue_overlay[:, :] = [100, 26, 26]  # Blue (BGR format)\n",
    "\n",
    "alpha = 0.5  # 0.0: fully transparent, 1.0: fully opaque\n",
    "\n",
    "# Blend the image with the blue overlay\n",
    "result_image = cv2.addWeighted(image, 1 - alpha, blue_overlay, alpha, 0)\n",
    "kernel_size = (25, 25)  # Kernel size for the average blur filter\n",
    "average_blur_image = cv2.blur(result_image, kernel_size)\n",
    "gaussian_blur_image = cv2.GaussianBlur(result_image, kernel_size, 0)\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Blue Image', result_image)\n",
    "cv2.imshow('average blur', average_blur_image)\n",
    "cv2.imshow('gaussian blur', gaussian_blur_image)\n",
    "                   \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b1af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image1=cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "image2=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg')\n",
    "width=700\n",
    "height=300\n",
    "resized_image1=cv2.resize(image1,(width,height))\n",
    "resized_image2=cv2.resize(image2,(width,height))\n",
    "img3=cv2.add(resized_image1,resized_image2)\n",
    "cv2.imshow('Original Image', img3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2b10c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image1=cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "image2=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg')\n",
    "width=800\n",
    "height=400\n",
    "resized_image1=cv2.resize(image1,(width,height))\n",
    "resized_image2=cv2.resize(image2,(width,height))\n",
    "img3=cv2.addWeighted(resized_image1,0.6,resized_image2,0.4,0)\n",
    "cv2.imshow('Original Image', img3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0c0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image1=cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "image2=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg')\n",
    "width=800\n",
    "height=400\n",
    "resized_image1=cv2.resize(image1,(width,height))\n",
    "resized_image2=cv2.resize(image2,(width,height))\n",
    "alpha = 0.5 \n",
    "blended_image = cv2.addWeighted(resized_image1, alpha, resized_image2, 1 - alpha, 0)\n",
    "cv2.imshow(\"Blended Image\", blended_image)\n",
    "cv2.imwrite(\"Blended Image.jpg\",blended_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf480fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image1=cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "image2=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg')\n",
    "width=700\n",
    "height=300\n",
    "resized_image1=cv2.resize(image1,(width,height))\n",
    "resized_image2=cv2.resize(image2,(width,height))\n",
    "img3=cv2.multiply(resized_image1,resized_image2)\n",
    "cv2.imshow('multiply Image', img3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98952025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image1=cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "image2=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg')\n",
    "width=700\n",
    "height=300\n",
    "resized_image1=cv2.resize(image1,(width,height))\n",
    "resized_image2=cv2.resize(image2,(width,height))\n",
    "img3=resized_image1+resized_image2\n",
    "cv2.imshow('New Image', img3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf8cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image1=cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "image2=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg')\n",
    "width=700\n",
    "height=300\n",
    "img1=cv2.resize(image1,(width,height))\n",
    "img2=cv2.resize(image2,(width,height))\n",
    "img3=cv2.multiply(img1,img2)\n",
    "img4=np.multiply(img1,img2)\n",
    "cv2.imshow('New Image', img3)\n",
    "cv2.imshow('New Image(using numpy)', img4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a69444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg')\n",
    "canny_edges = cv2.Canny(image, 50, 150)  # Adjust the threshold values as needed\n",
    "cv2.imshow('Canny Image',canny_edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be0ffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "canny_edges = cv2.Canny(image, 50, 150)  # Adjust the threshold values as needed\n",
    "cv2.imshow('Canny Image',canny_edges)\n",
    "contours, _ = cv2.findContours(canny_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a copy of the original image to draw contours on\n",
    "contour_image = canny_edges.copy()\n",
    "\n",
    "cv2.drawContours(canny_edges, contours, -1, (0, 255, 255), 20)\n",
    "\n",
    "cv2.imshow('Image with Contours', contour_image)\n",
    "print(len(contours))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f061ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((1400,800,3),dtype=np.uint8)\n",
    "cv2.circle(image, (400, 150), 50, (255, 0, 0), -1)\n",
    "cv2.imshow(\"TestImages2 for crashing\",image)\n",
    "cv2.imwrite(\"out.jpg\",image)\n",
    "img=cv2.imread(\"out.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img, contours, -1, (225, 255, 10), 2)\n",
    "cv2.imshow('Image with Contours', img)\n",
    "print(len(contours))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9521c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((1400,800,3),dtype=np.uint8)\n",
    "cv2.rectangle(image, (400, 150), (300,300), (255, 200, 0), -1)\n",
    "cv2.imshow(\"TestImages2 for crashing\",image)\n",
    "cv2.imwrite(\"out.jpg\",image)\n",
    "img=cv2.imread(\"out.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img, contours, -1, (225, 255, 10), 2)\n",
    "cv2.imshow('Image with Contours', img)\n",
    "print(len(contours))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b520aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lower_threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m adaptive_threshold_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39madaptiveThreshold(image, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mADAPTIVE_THRESH_MEAN_C, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      6\u001b[0m _, otsu_threshold_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(image, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY \u001b[38;5;241m+\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTHRESH_OTSU)\n\u001b[1;32m----> 7\u001b[0m inrange_threshold_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39minRange(image, lower_threshold, upper_threshold)\n\u001b[0;32m      9\u001b[0m binary_threshold_image\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(binary_threshold_image,(\u001b[38;5;241m400\u001b[39m,\u001b[38;5;241m400\u001b[39m))\n\u001b[0;32m     10\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m, adaptive_threshold_image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lower_threshold' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "_, binary_threshold_image = cv2.threshold(image, 140, 255, cv2.THRESH_BINARY)\n",
    "adaptive_threshold_image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "_, otsu_threshold_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "_,inrange_threshold_image = cv2.inRange(image, lower_threshold, upper_threshold)\n",
    "\n",
    "binary_threshold_image=cv2.resize(binary_threshold_image,(400,400))\n",
    "cv2.imshow(\"Test\", binary_threshold_image)\n",
    "cv2.imshow(\"Test1\", adaptive_threshold_image)\n",
    "cv2.imshow(\"Test2\", otsu_threshold_image)\n",
    "cv2.imshow(\"Test3\", inrange_threshold_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d46471a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "_, binary_threshold_image = cv2.threshold(image, 140, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "binary_threshold_image=cv2.resize(binary_threshold_image,(400,400))\n",
    "cv2.imshow(\"Test\", binary_threshold_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdf2cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "adaptive_threshold_image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "#binary_threshold_image=cv2.resize(binary_threshold_image,(400,400))\n",
    "cv2.imshow(\"Test1\", adaptive_threshold_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fafec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "_, otsu_threshold_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Test2\", otsu_threshold_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image=cv2.imread('C:/Users/Veena/Downloads/HP2.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "_,inrange_threshold_image = cv2.inRange(image, lower_threshold, upper_threshold)\n",
    "\n",
    "binary_threshold_image=cv2.resize(binary_threshold_image,(400,400))\n",
    "cv2.imshow(\"Test3\", inrange_threshold_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c462ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/numberplate.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow('Original Grayscale Image', image)\n",
    "\n",
    "# Define kernel for operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Erosion: Erodes away the boundaries of foreground objects\n",
    "erosion_image = cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow('Erosion Image', erosion_image)\n",
    "\n",
    "# Dilation: Expands the boundaries of foreground objects\n",
    "dilation_image = cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow('Dilation Image', dilation_image)\n",
    "\n",
    "# Opening: Erosion followed by dilation, useful for noise reduction\n",
    "opening_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imshow('Opening Image', opening_image)\n",
    "\n",
    "# Closing: Dilation followed by erosion, useful for closing small holes in objects\n",
    "closing_image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cv2.imshow('Closing Image', closing_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a9908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow('Original Grayscale Image', image)\n",
    "\n",
    "# Define kernel for operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Erosion: Erodes away the boundaries of foreground objects\n",
    "erosion_image = cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow('Erosion Image', erosion_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d3ec0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/bean.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "hist_image = np.zeros((100, 256), dtype=np.uint8)\n",
    "cv2.normalize(histogram, histogram, 0, hist_image.shape[0], cv2.NORM_MINMAX)\n",
    "\n",
    "for i in range(256):\n",
    "    cv2.line(hist_image, (i, hist_image.shape[0]), (i, hist_image.shape[0] - int(histogram[i])), 255)\n",
    "\n",
    "cv2.imshow('Histogram', hist_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "261f1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/bean.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "hist_image = np.zeros((100, 256), dtype=np.uint8)\n",
    "cv2.normalize(histogram, histogram, 0, hist_image.shape[0], cv2.NORM_MINMAX)\n",
    "\n",
    "for i in range(256):\n",
    "    cv2.line(hist_image, (i, hist_image.shape[0]), (i, hist_image.shape[0] - int(histogram[i])), 255)\n",
    "\n",
    "cv2.imshow('Histogram', hist_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa84096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "main_image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "\n",
    "template = cv2.imread('newImage.jpg')\n",
    "result = cv2.matchTemplate(main_image, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Find the location of the matched area\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "# Draw a rectangle around the matched area\n",
    "h, w, _ = template.shape\n",
    "cv2.rectangle(main_image, max_loc, (max_loc[0] + w, max_loc[1] + h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Matching Result', cv2.resize(main_image,(800,800)))\n",
    "cv2.imshow(\"Org Image\",template)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4570074",
   "metadata": {},
   "source": [
    "# Day3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42510df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "main_image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg')\n",
    "\n",
    "template = cv2.imread('newImage.jpg')\n",
    "result = cv2.matchTemplate(main_image, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Find the location of the matched area\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "# Draw a rectangle around the matched area\n",
    "h, w, _ = template.shape\n",
    "cv2.rectangle(main_image, max_loc, (max_loc[0] + w, max_loc[1] + h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Matching Result', cv2.resize(main_image,(800,800)))\n",
    "cv2.imshow(\"Org Image\",template)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "im1=cv2.resize(cv2.imread(\"C:/Users/Veena/Downloads/HP1.jpg\",cv2.IMREAD_GRAYSCALE),(480,480))\n",
    "im2=cv2.resize(cv2.imread(\"C:/Users/Veena/Downloads/HP2.jpg\",cv2.IMREAD_GRAYSCALE),(480,480))\n",
    "print(im1.shape)\n",
    "print(im2.shape)\n",
    "W,H=im1.shape[:2]\n",
    "#Read Images and Convert them to Grayscale\n",
    "match=cv2.matchTemplate(im1,im2,method=cv2.TM_CCOEFF_NORMED)\n",
    "threshold=126\n",
    "(x,y)=np.where(match>=threshold)\n",
    "boxes=[]\n",
    "for(a,b) in zip(x,y):\n",
    "    boxes.append((x,y,x+W,y+H))\n",
    "    \n",
    "for(a1,a2,a3,a4) in boxes:\n",
    "    cv2.rectangle(im1,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "cv2.imshow(\"Final Output\",im1)\n",
    "cv2.imshow(\"Template Output 2\",im2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP2(1).jpg')\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "\n",
    "# Construct the Gaussian pyramid\n",
    "gaussian_pyramid = [image]\n",
    "for i in range(5):\n",
    "    image = cv2.pyrDown(image)\n",
    "    gaussian_pyramid.append(image)\n",
    "\n",
    "for i, level_image in enumerate(gaussian_pyramid):\n",
    "    cv2.imshow(f'Gaussian Pyramid Level {i}', level_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6bb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP2(1).jpg')\n",
    "\n",
    "\n",
    "gaussian_pyramid = [image]\n",
    "for i in range(6):\n",
    "    image = cv2.pyrDown(image)\n",
    "    gaussian_pyramid.append(image)\n",
    "\n",
    "for i, level_image in enumerate(gaussian_pyramid):\n",
    "    cv2.imshow(f'Gaussian Pyramid Level {i}', level_image)\n",
    "# Construct the Laplacian pyramid from the Gaussian pyramid\n",
    "laplacian_pyramid = [gaussian_pyramid[5]]\n",
    "for i in range(5, 0, -1):\n",
    "    expanded = cv2.pyrUp(gaussian_pyramid[i])\n",
    "    laplacian = cv2.subtract(gaussian_pyramid[i - 1], expanded)\n",
    "    laplacian_pyramid.append(laplacian)\n",
    "\n",
    "for i, level_image in enumerate(laplacian_pyramid):\n",
    "    cv2.imshow(f'Laplacian Pyramid Level {i}', level_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(''C:/Users/Veena/Downloads/HP2(1).jpg')\n",
    "\n",
    "\n",
    "gaussian_pyramid = [image]\n",
    "for i in range(6):\n",
    "    image = cv2.pyrDown(image)\n",
    "    gaussian_pyramid.append(image)\n",
    "\n",
    "for i, level_image in enumerate(gaussian_pyramid):\n",
    "    cv2.imshow(f'Gaussian Pyramid Level {i}', level_image)\n",
    "# Construct the Laplacian pyramid from the Gaussian pyramid\n",
    "laplacian_pyramid = [gaussian_pyramid[5]]\n",
    "for i in range(5, 0, -1):\n",
    "    expanded = cv2.pyrUp(gaussian_pyramid[i])\n",
    "    laplacian = cv2.subtract(cv2.resize(gaussian_pyramid[i],(480,480)),cv2.resize(expanded,(480,480)))\n",
    "    laplacian_pyramid.append(laplacian)\n",
    "\n",
    "for i, level_image in enumerate(laplacian_pyramid):\n",
    "    cv2.imshow(f'Laplacian Pyramid Level {i}', level_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fbcb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: image200x200.jpg\n",
      "Saved: image450x450.jpg\n",
      "Saved: image320x320.jpg\n",
      "Saved: image500x500.jpg\n",
      "Saved: image600x600.jpg\n",
      "Saved: image750x750.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/HP1.jpg\")\n",
    "cvtd2=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow(\"HSV Image\",cvtd2)\n",
    "target_sizes = [200, 450, 320, 500,600,750]  \n",
    "for size in target_sizes:\n",
    "    resized_image = cv2.resize(cvtd2, (size, size))\n",
    "    filename = f\"image{size}x{size}.jpg\"\n",
    "    cv2.imwrite(filename, resized_image)\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406927d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: image480x480.jpg\n",
      "Saved: image720x720.jpg\n",
      "Saved: image960x960.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "original_image = cv2.imread(\"C:/Users/Veena/Downloads/HP1.jpg\")\n",
    "blurred_image = cv2.GaussianBlur(original_image, (15, 15), 0)\n",
    "target_sizes = [480, 720, 960]  # Add more sizes as needed\n",
    "for size in target_sizes:\n",
    "    resized_image = cv2.resize(blurred_image, (size, size))\n",
    "    filename = f\"image{size}x{size}.jpg\"\n",
    "    cv2.imwrite(filename, resized_image)\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11eac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Read the original image\n",
    "image = cv2.imread('hp.jpg')\n",
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "for i in range(5):\n",
    "    image = cv2.pyrDown(image)\n",
    "    cv2.imshow(f'Gaussian Pyramid Level {i}', image)\n",
    "    cv2.imwrite(f'{image.shape[1]}x{image.shape[0]}.jpg', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347960c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_pyramid = [image1]\n",
    "for _ in range(3):  \n",
    "    image1 = cv2.pyrDown(image1)\n",
    "    gaussian_pyramid.append(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80b7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "original_image = cv2.imread(\"C:/Users/Veena/Downloads/HP.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "_, binary_mask = cv2.threshold(original_image, 169, 255, cv2.THRESH_BINARY_INV)\n",
    "result_image = cv2.merge([binary_mask, binary_mask, binary_mask])\n",
    "blurred_image = cv2.bilateralFilter(result_image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Thresholded Image\", result_image)\n",
    "cv2.imshow(\"Blurred Image\", blurred_image)\n",
    "cv2.imwrite(\"final_image.jpg\", blurred_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85229278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "circles = cv2.HoughCircles(\n",
    "    blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50, param1=200, param2=30, minRadius=10, maxRadius=50\n",
    ")\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for circle in circles[0, :]:\n",
    "        cv2.circle(image, (circle[0], circle[1]), circle[2], (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('Hough Circles', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc80a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/HP1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "cv2.imshow(\"Test\",cv2.Canny(blurred,10,50))\n",
    "circles = cv2.HoughCircles(\n",
    "    blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50, param1=200, param2=30, minRadius=10, maxRadius=50\n",
    ")\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for circle in circles[0, :]:\n",
    "        cv2.circle(image, (circle[0], circle[1]), circle[2], (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('Hough Circles', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd120d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = cv2.HoughCircles(\n",
    "    blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50, param1=200, param2=30, minRadius=10, maxRadius=50\n",
    ")\n",
    "\n",
    "\n",
    "1)Finds edges in an image using Canny Edge Detecttion\n",
    "2) Here we set the threshold \n",
    "1)Finds edges in an image using Canny Edge Detecttion\n",
    "2) Here we set the threshold for the min and max radius as defined in \n",
    "cv2.HoughCircles(\n",
    "    blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50, param1=200, param2=30, minRadius=10, maxRadius=50\n",
    ")\n",
    "\n",
    "3) Accumulator returns the circles which match the radii and centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eedf5289",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/winter.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,150,250)\n",
    "cv2.imshow('canny',edges)\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 150,maxLineGap=30)\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow(str((lines)), image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5dc4d",
   "metadata": {},
   "source": [
    "# Watershed Algorithm\n",
    "1)Preprocessing\n",
    "2)Apply Thresholding\n",
    "3)Morphological Transformations (DeNoising)\n",
    "/ Removing Noise | Dilate/Erode\n",
    "\n",
    "4)Creating a Marker Image\n",
    "5)Apply Watershed Algo\n",
    "6)Display Segemented\n",
    "#Reason to Use Watershed \n",
    "#To get a segemented Image Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce7ca899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/winter.jpg')\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, thresh = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "# Perform morphological operations to clean the image\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "# Identify the background area\n",
    "sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "# Perform distance transform\n",
    "dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "# Threshold the distance transform to obtain sure foreground\n",
    "_, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "# Subtract sure foreground from sure background to obtain unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "# Marker labeling for watershed algorithm\n",
    "_, markers = cv2.connectedComponents(sure_fg)\n",
    "markers = markers + 1\n",
    "markers[unknown == 255] = 0\n",
    "# Apply watershed algorithm\n",
    "cv2.watershed(image, markers)\n",
    "image[markers == -1] = [0, 0, 255]  # Mark watershed boundaries in red\n",
    "\n",
    "cv2.imshow('Segmented Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c9771b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/winter.jpg')\n",
    "mask = np.zeros(image.shape[:2], np.uint8)\n",
    "# Define the rectangle for initial GrabCut algorithm\n",
    "rect = (50, 50, 450, 290)\n",
    "# Initialize the foreground and background models\n",
    "bgd_model = np.zeros((1, 65), np.float64)\n",
    "fgd_model = np.zeros((1, 65), np.float64)\n",
    "# Apply GrabCut algorithm\n",
    "cv2.grabCut(image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
    "# Modify the mask to create a binary mask for foreground and background\n",
    "mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "# Multiply the original image with the binary mask to extract the foreground\n",
    "result = image * mask2[:, :, np.newaxis]\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Foreground Extraction', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc54ad59",
   "metadata": {},
   "source": [
    "# Day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b8d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('C:/Users/Veena/Downloads/hp4.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('C:/Users/Veena/Downloads/hp3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#Create ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "#get keypoints and descriptors\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "# Create BFMatcher (Brute-Force Matcher) object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(descriptors1, descriptors2)\n",
    "# Sort them based on distance\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imshow('Matches', img_matches)\n",
    "\n",
    "# Extract matched keypoints\n",
    "src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "homography, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "\n",
    "# Apply Homography to the template image corners to find the object\n",
    "h, w = img1.shape\n",
    "corners = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "transformed_corners = cv2.perspectiveTransform(corners, homography)\n",
    "img2_rectangle = cv2.polylines(img2, [np.int32(transformed_corners)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('Object Detection', img2_rectangle)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0c2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/hp3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# Create a SIFT object\n",
    "sift = cv2.SIFT_create()\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "# Draw keypoints on the image\n",
    "image_with_keypoints = cv2.drawKeypoints(image, keypoints, None)\n",
    "cv2.imshow('Image with SIFT Keypoints', image_with_keypoints)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af185760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread('C:/Users/Veena/Downloads/hp3.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "flt=np.float32(img)\n",
    "\n",
    "corners=cv2.cornerHarris(flt,2,3,0.05)\n",
    "corners=cv2.dilate(corners,None)\n",
    "img[corners > 0.01 * corners.max()]=[105]\n",
    "cv2.imshow(\"Finakl\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9abcfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veena\\AppData\\Local\\Temp\\ipykernel_19964\\2584734691.py:8: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  corners = np.int0(corners)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/hp4.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# Detect Shi-Tomasi corners\n",
    "corners = cv2.goodFeaturesToTrack(image, maxCorners=25, qualityLevel=0.01, minDistance=10)\n",
    "# Convert corners to integers\n",
    "corners = np.int0(corners)\n",
    "# Draw circles around the detected corners\n",
    "image_with_corners = image.copy()\n",
    "for corner in corners:\n",
    "    x, y = corner.ravel()\n",
    "    cv2.circle(image_with_corners, (x, y), 6, 18, -1)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Image with Shi-Tomasi Corners', image_with_corners)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f89b565",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Veena/Downloads/hp4.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create a SURF object\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m surf \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mxfeatures2d\u001b[38;5;241m.\u001b[39mSURF_create()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Detect keypoints and compute descriptors\u001b[39;00m\n\u001b[0;32m      6\u001b[0m keypoints, descriptors \u001b[38;5;241m=\u001b[39m surf\u001b[38;5;241m.\u001b[39mdetectAndCompute(image, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/hp4.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# Create a SURF object\n",
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints, descriptors = surf.detectAndCompute(image, None)\n",
    "# Draw keypoints on the image\n",
    "image_with_keypoints = cv2.drawKeypoints(image, keypoints, None)\n",
    "cv2.imshow('Image with SURF Keypoints', image_with_keypoints)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "815a28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:/Users/Veena/Downloads/winter.jpg')\n",
    "\n",
    "gaussian_pyramid = [image]\n",
    "for i in range(6):\n",
    "    image = cv2.pyrDown(image)\n",
    "    gaussian_pyramid.append(image)\n",
    "\n",
    "for i, level_image in enumerate(gaussian_pyramid):\n",
    "    cv2.imshow(f'Gaussian Pyramid Level {i}', level_image)\n",
    "# Construct the Laplacian pyramid from the Gaussian pyramid\n",
    "laplacian_pyramid = [gaussian_pyramid[5]]\n",
    "for i in range(5, 0, -1):\n",
    "    expanded = cv2.pyrUp(gaussian_pyramid[i])\n",
    "    laplacian = cv2.subtract(cv2.resize(gaussian_pyramid[i],(480,480)),cv2.resize(expanded,(480,480)))\n",
    "    laplacian_pyramid.append(laplacian)\n",
    "\n",
    "for i, level_image in enumerate(laplacian_pyramid):\n",
    "    cv2.imshow(f'Laplacian Pyramid Level {i}', level_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(60, 110): \n",
    "    blue_overlay[:, :] = [int(x+152), x+68, x+68] \n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "result_image = cv2.addWeighted(image, 1-alpha, blue_overlay, alpha, 0)\n",
    "\n",
    "images.append(result_image)\n",
    "\n",
    "for (x, y) in zip(images, range(len(images))): \n",
    "    cv2.imshow(f'Original Image{y}', x)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vid=cv2.VideoCapture(0)\n",
    "while vid.isOpened():\n",
    "    _,frame=vid.read()\n",
    "    frame=cv2.resize(frame,(640,640))\n",
    "    cv2.imshow(\"Camera Capture\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cab4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vid=cv2.VideoCapture('hw.mp4')\n",
    "while vid.isOpened():\n",
    "    _,frame=vid.read()\n",
    "    frame=cv2.resize(frame,(640,640),interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(\"Camera Capture\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7a01567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "images=[img for img in os.listdir(os.getcwd()) if img.endswith(\".jpg\")]\n",
    "\n",
    "vid=cv2.VideoWriter(\"myVideo.avi\",0,1,(480,480))\n",
    "for f in images:\n",
    "    vid.write(cv2.resize(cv2.imread(os.path.join(os.getcwd(),f)),(480,480)))\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bbc716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Specify the directory path where your images are located\n",
    "image_directory = \"C:/Users/Veena/Downloads\"\n",
    "\n",
    "# Get a list of image files in the directory\n",
    "images = [img for img in os.listdir(image_directory) if img.endswith(\".jpg\")]\n",
    "\n",
    "# Define the VideoWriter parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = 1\n",
    "size = (480, 480)\n",
    "\n",
    "# Create a VideoWriter object\n",
    "vid = cv2.VideoWriter(\"myVideo.avi\", fourcc, fps, size)\n",
    "\n",
    "# Iterate through the images and add them to the video\n",
    "for img_name in images:\n",
    "    img_path = os.path.join(image_directory, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Resize the image to match the video size\n",
    "    resized_img = cv2.resize(img, size)\n",
    "\n",
    "    # Write the resized image to the video\n",
    "    vid.write(resized_img)\n",
    "\n",
    "# Release the VideoWriter\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e951604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blended Image.jpg', 'final_image.jpg', 'GrayScale Image.jpg', 'HSV Image.jpg', 'image200x200.jpg', 'image320x320.jpg', 'image450x450.jpg', 'image480x480.jpg', 'image500x500.jpg', 'image600x600.jpg', 'image720x720.jpg', 'image750x750.jpg', 'image960x960.jpg', 'LAB Image.jpg', 'newImage.jpg', 'Original Image.jpg', 'out.jpg', 'RGB Image.jpg']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cv2,os\n",
    "image = cv2.imread(\"C:/Users/Veena/Downloads/hp4.jpg\")\n",
    "cvtd=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "cvtd1=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cvtd2=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "cvtd3=cv2.cvtColor(image,cv2.COLOR_BGR2LAB)\n",
    "cv2.imwrite(\"Original Image.jpg\",image)\n",
    "cv2.imwrite(\"RGB Image.jpg\",cvtd)\n",
    "cv2.imwrite(\"GrayScale Image.jpg\",cvtd1)\n",
    "cv2.imwrite(\"HSV Image.jpg\",cvtd2)\n",
    "cv2.imwrite(\"LAB Image.jpg\",cvtd3)\n",
    "\n",
    "images=[img for img in os.listdir(os.getcwd()) if img.endswith(\".jpg\")]\n",
    "print(images)\n",
    "vid=cv2.VideoWriter(\"Video1.avi\",0,1,(480,480))\n",
    "for f in images:\n",
    "    vid.write(cv2.resize(cv2.imread(os.path.join(os.getcwd(),f)),(480,480)))\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ce43c1",
   "metadata": {},
   "source": [
    "# Day_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caeb6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vid=cv2.VideoCapture('C:/Users/Veena/Desktop/OPENCV')\n",
    "while vid.isOpened():\n",
    "    _,frame=vid.read()\n",
    "    frame=cv2.resize(frame,(640,640),interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(\"Camera Capture\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "cap=cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "print(cv2.CAP_PROP_FPS)\n",
    "print(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "print(cv2.CAP_PROP_FRAME_COUNT)\n",
    "print(cv2.CAP_PROP_FORMAT)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    #cv2.imshow(f'Video Frame {count}', frame)\n",
    "    #cv2.waitKey(0)\n",
    "  \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3431eb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "3\n",
      "7\n",
      "8\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "1.0\n",
      "480.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "#using cap.get() we gets details for the read video details, otherwise default values are shown\n",
    "#cap.get(cv2.CAP_PROP_FPS)) ? for actual fps-for frame\n",
    "import cv2,os\n",
    "cap=cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "print(cv2.CAP_PROP_FPS)\n",
    "print(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "print(cv2.CAP_PROP_FRAME_COUNT)\n",
    "print(cv2.CAP_PROP_FORMAT)\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    print(cap.get(cv2.CAP_PROP_FPS))\n",
    "    print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db045fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "print(vid.get(cv2.CAP_PROP_FPS))\n",
    "print(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(vid.get(cv2.CAP_PROP_AUDIO_TOTAL_CHANNELS))\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    if count >=10:\n",
    "        break\n",
    "    cv2.imshow(f\"Frame {count}\",frame)\n",
    "    cv2.imwrite(f\"Frame_{count}.jpg\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    count += 1\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d59aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "count=0\n",
    "fps=int(vid.get(cv2.CAP_PROP_FPS))\n",
    "output=cv2.VideoWriter(\"outputvideo.avi\",0, 5, (480, 480))\n",
    "startsec=2\n",
    "endsec= startsec+10\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if startsec<= count <= endsec:\n",
    "        blurr = cv2.GaussianBlur(frame,(25, 25), 0)\n",
    "        output.write(blurr)\n",
    "    else:\n",
    "        output.write(frame)\n",
    "    count += 1\n",
    "vid.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aecc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Write a program to read a video and ask user for the time from where he/ she wants the video to be trimmed. \n",
    "So from that point of time, trim the video and save it as new video on the system.\"\"\"\n",
    "import cv2\n",
    "\n",
    "def trim_video(input_path, output_path, start_time_sec):\n",
    "    # Open the video file\n",
    "    vid = cv2.VideoCapture(input_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Calculate the starting frame index based on the specified start time\n",
    "    start_frame = int(start_time_sec * fps)\n",
    "\n",
    "    # Set the video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Process each frame starting from the specified time\n",
    "    for frame_num in range(start_frame, total_frames):\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release video capture and writer\n",
    "    vid.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input video file path\n",
    "    input_video_path = 'input_video.mp4'\n",
    "\n",
    "    # Output video file path (trimmed video will be saved here)\n",
    "    output_video_path = 'output_trimmed_video.avi'\n",
    "\n",
    "    # Get user input for the start time of trimming\n",
    "    start_time_input = input(\"Enter the start time in seconds (e.g., 10): \")\n",
    "    \n",
    "    try:\n",
    "        start_time_sec = float(start_time_input)\n",
    "        trim_video(input_video_path, output_video_path, start_time_sec)\n",
    "        print(f\"Video trimmed successfully and saved as {output_video_path}\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input for start time. Please enter a valid number.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vid = cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "start = int(input('Enter start value')) \n",
    "end = int(input('Enter end value'))\n",
    "frames1 =[]\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    if start <= count <= end:\n",
    "        frames1.append(frame)\n",
    "    count += 1\n",
    "vid.release()\n",
    "output_vid = cv2.VideoWriter(\"trimmedVideo.avi\", 0, 1, (480, 480))\n",
    "for f in frames1:\n",
    "    output_vid.write(f)\n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
